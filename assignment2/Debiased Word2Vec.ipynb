{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 630: Homework 2: Word2Vec\n",
    "\n",
    "This homework will have you implementing word2vec using PyTorch and let you familiarize yourself with building more complex neural networks and the larger PyTorch development infrastructure.\n",
    "\n",
    "Broadly, this homework consists of a few major parts:\n",
    "1. Implement a `Corpus` class that will load the dataset and convert it to a sequence of token ids\n",
    "2. Implement negative sampling to select tokens to be used as negative examples of words in the context\n",
    "3. Create your dataset of positive and negative examples per context and load it into PyTorch's `DataLoader` to use for sampling\n",
    "4. Implement a `Word2Vec` class that is a PyTorch neural network\n",
    "5. Implement a training loop that samples a _batch_ of target words and their respective positive/negative context words\n",
    "6. Implement rare word removal and frequent word subsampling\n",
    "7. Run your model on the full dataset for at least one epoch\n",
    "8. Do the exploratory parts of the homework\n",
    "9. Make a copy of this notebook and change your implementation so it learns word vectors with less bias\n",
    "\n",
    "After Step 5, you should be able to run your word2vec implementation on a small dataset and verify that it's learning correctly. Once you can verify everything is working, proceed with steps 6 and beyond. **Please note that this list is a general sketch and the homework PDF has the full list/description of to-dos and all your deliverables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1809f285c30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from tqdm.auto import tqdm, trange\n",
    "from collections import Counter\n",
    "import random\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Helpful for computing cosine similarity--Note that this is NOT a similarity!\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Handy command-line argument parsing\n",
    "import argparse\n",
    "\n",
    "# Sort of smart tokenization\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# We'll use this to save our models\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#\n",
    "# IMPORTANT NOTE: Always set your random seeds when dealing with stochastic\n",
    "# algorithms as it lets your bugs be reproducible and (more importantly) it lets\n",
    "# your results be reproducible by others.\n",
    "#\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a class to hold the data\n",
    "\n",
    "Before we get to training word2vec, we'll need to process the corpus into some representation. The `Corpus` class will handle much of the functionality for corpus reading and keeping track of which word types belong to which ids. The `Corpus` class will also handle the crucial functionality of generating negative samples for training (i.e., randomly-sampled words that were not in the target word's context).\n",
    "\n",
    "Some parts of this class can be completed after you've gotten word2vec up and running, so see the notes below and the details in the homework PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        \n",
    "        # These state variables become populated with function calls\n",
    "        #\n",
    "        # 1. load_data()\n",
    "        # 2. generate_negative_sampling_table()\n",
    "        #\n",
    "        # See those functions for how the various values get filled in\n",
    "\n",
    "        self.word_to_index = {} # word to unique-id\n",
    "        self.index_to_word = {} # unique-id to word\n",
    "\n",
    "        # How many times each word occurs in our data after filtering\n",
    "        self.word_counts = Counter()\n",
    "\n",
    "        # A utility data structure that lets us quickly sample \"negative\"\n",
    "        # instances in a context. This table contains unique-ids\n",
    "        self.negative_sampling_table = []\n",
    "        \n",
    "        # The dataset we'll use for training, as a sequence of unqiue word\n",
    "        # ids. This is the sequence across all documents after tokens have been\n",
    "        # randomly subsampled by the word2vec preprocessing step\n",
    "        self.full_token_sequence_as_ids = []\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        '''\n",
    "        Tokenize the document and returns a list of the tokens\n",
    "        '''\n",
    "        return self.tokenizer.tokenize(text)        \n",
    "\n",
    "    def load_data(self, file_name, min_token_freq):\n",
    "        '''\n",
    "        Reads the data from the specified file as long long sequence of text\n",
    "        (ignoring line breaks) and populates the data structures of this\n",
    "        word2vec object.\n",
    "        '''\n",
    "\n",
    "        # Step 1: Read in the file and create a long sequence of tokens for\n",
    "        # all tokens in the file\n",
    "        print('Reading data and tokenizing')\n",
    "        with open(file_name, encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            \n",
    "            cachedStopWords = stopwords.words('english')\n",
    "            \n",
    "            raw_tokens = self.tokenize(text)\n",
    "            raw_tokens_without_sw = [word for word in raw_tokens if not word in cachedStopWords]\n",
    "            all_tokens = [word.lower() for word in raw_tokens_without_sw]\n",
    "            \n",
    "#             all_tokens = [word.lower() for word in raw_tokens]\n",
    "    \n",
    "        # Step 2: Count how many tokens we have of each type\n",
    "        print('Counting token frequencies')\n",
    "        freqs = Counter(all_tokens)\n",
    "        \n",
    "        # Step 3: Replace all tokens below the specified frequency with an <UNK>\n",
    "        # token. \n",
    "        #\n",
    "        # NOTE: You can do this step later if needed\n",
    "        print(\"Performing minimum thresholding\")\n",
    "        UNK_dict = {}\n",
    "        for index in range(len(all_tokens)):\n",
    "            if freqs[all_tokens[index]] < min_token_freq:\n",
    "                UNK_dict[all_tokens[index]] = index\n",
    "                all_tokens[index] = '<UNK>'\n",
    "                \n",
    "        # Step 4: update self.word_counts to be the number of times each word\n",
    "        # occurs (including <UNK>)\n",
    "        self.word_counts = Counter(all_tokens)\n",
    "        \n",
    "        # Step 5: Create the mappings from word to unique integer ID and the\n",
    "        # reverse mapping. \n",
    "\n",
    "        n = 0\n",
    "        for i in Counter(all_tokens).keys():\n",
    "            self.word_to_index[i] = n\n",
    "            self.index_to_word[n] = i\n",
    "\n",
    "            n += 1\n",
    "        \n",
    "        # Step 6: Compute the probability of keeping any particular *token* of a\n",
    "        # word in the training sequence, which we'll use to subsample. This subsampling\n",
    "        # avoids having the training data be filled with many overly common words\n",
    "        # as positive examples in the context\n",
    "        postive_subsample = {}\n",
    "        sum_word_counts = sum(self.word_counts.values())\n",
    "        for word in self.word_to_index:\n",
    "            \n",
    "            pw = self.word_counts[word] / sum_word_counts\n",
    "            pkw = (np.sqrt(pw/0.001) + 1)*(0.001/pw)\n",
    "            postive_subsample[self.word_to_index[word]] = pkw\n",
    "                        \n",
    "        # Step 7: process the list of tokens (after min-freq filtering) to fill\n",
    "        # a new list self.full_token_sequence_as_ids where \n",
    "        #\n",
    "        # (1) we probabilistically choose whether to keep each *token* based on the\n",
    "        # subsampling probabilities (note that this does not mean we drop # \n",
    "        # an entire word!) and \n",
    "        #\n",
    "        # (2) all tokens are convered to their unique ids for faster training.\n",
    "        #\n",
    "        # NOTE: You can skip the subsampling part and just do step 2 to get\n",
    "        # your model up and running.\n",
    "        \n",
    "        for word in all_tokens:\n",
    "            if postive_subsample[self.word_to_index[word]] > np.random.rand():\n",
    "                self.full_token_sequence_as_ids.append(self.word_to_index[word])\n",
    "        \n",
    "        # NOTE 2: You will perform token-based subsampling based on the probabilities in\n",
    "        # word_to_sample_prob. When subsampling, you are modifying the sequence itself \n",
    "        # (like deleting an item in a list). This action effectively makes the context\n",
    "        # window  larger for some target words by removing context words that are common\n",
    "        # from a particular context before the training occurs (which then would now include\n",
    "        # other words that were previously just outside the window).\n",
    "\n",
    "\n",
    "        # Helpful print statement to verify what you've loaded\n",
    "        print('Loaded all data from %s; saw %d tokens (%d unique)' \\\n",
    "              % (file_name, len(self.full_token_sequence_as_ids),\n",
    "                 len(self.word_to_index)))\n",
    "        \n",
    "    def generate_negative_sampling_table(self, exp_power=0.75, table_size=1e6):\n",
    "        '''\n",
    "        Generates a big list data structure that we can quickly randomly index into\n",
    "        in order to select a negative training example (i.e., a word that was\n",
    "        *not* present in the context). \n",
    "        '''       \n",
    "        \n",
    "        # Step 1: Figure out how many instances of each word need to go into the\n",
    "        # negative sampling table. \n",
    "        #\n",
    "        # HINT: np.power and np.fill might be useful here        \n",
    "        print(\"Generating sampling table\")\n",
    "        \n",
    "        sum_of_weight = np.sum(np.power(list(self.word_counts.values()), exp_power))\n",
    "        number_of_instances_dict = {}\n",
    "        for word in self.word_to_index.keys():\n",
    "            word_prob = np.power(self.word_counts[word], exp_power) / sum_of_weight\n",
    "            number_of_instances_dict[word] = int(table_size * word_prob)\n",
    "        \n",
    "        \n",
    "        # Step 2: Create the table to the correct size. You'll want this to be a\n",
    "        # numpy array of type int\n",
    "\n",
    "\n",
    "        # Step 3: Fill the table so that each word has a number of IDs\n",
    "        # proportionate to its probability of being sampled.\n",
    "        #\n",
    "        # Example: if we have 3 words \"a\" \"b\" and \"c\" with probabilites 0.5,\n",
    "        # 0.33, 0.16 and a table size of 6 then our table would look like this\n",
    "        # (before converting the words to IDs):\n",
    "        #\n",
    "        # [ \"a\", \"a\", \"a\", \"b\", \"b\", \"c\" ]\n",
    "        #\n",
    "        for word, number in number_of_instances_dict.items():\n",
    "            self.negative_sampling_table += [self.word_to_index[word]] * number\n",
    "#             print(negative_sampling_table[:1000])\n",
    "            \n",
    "\n",
    "    def generate_negative_samples(self, cur_context_word_id, num_samples):\n",
    "        '''\n",
    "        Randomly samples the specified number of negative samples from the lookup\n",
    "        table and returns this list of IDs as a numpy array. As a performance\n",
    "        improvement, avoid sampling a negative example that has the same ID as\n",
    "        the current positive context word.\n",
    "        '''\n",
    "\n",
    "        results = []\n",
    "\n",
    "        while True:\n",
    "            rand_ids = random.sample(self.negative_sampling_table, num_samples)\n",
    "            if cur_context_word_id not in rand_ids:\n",
    "                results = rand_ids\n",
    "                break\n",
    "        # Create a list and sample from the negative_sampling_table to\n",
    "        # grow the list to num_samples, avoiding adding a negative example that\n",
    "        # has the same ID as the current context_word\n",
    "\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the corpus\n",
    "\n",
    "Now that we have code to turn the text into training data, let's do so. We've provided several files for you to help:\n",
    "\n",
    "* `wiki-bios.DEBUG.txt` -- use this to debug your corpus reader\n",
    "* `wiki-bios.10k.txt` -- use this to debug/verify the whole word2vec works\n",
    "* `wiki-bios.med.txt` -- use this when everything works to generate your vectors for later parts\n",
    "* `wiki-bios.HUGE.txt.gz` -- _do not use this_ unless (1) everything works and (2) you really want to test/explore. This file is not needed at all to do your homework.\n",
    "\n",
    "We recommend startin to debug with the first file, as it is small and fast to load (quicker to find bugs). When debugging, we recommend setting the `min_token_freq` argument to 2 so that you can verify that part of the code is working but you still have enough word types left to test the rest.\n",
    "\n",
    "You'll use the remaining files later, where they're described.\n",
    "\n",
    "In the next cell, create your `Corpus`, read in the data, and generate the negative sampling table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data and tokenizing\n",
      "Counting token frequencies\n",
      "Performing minimum thresholding\n",
      "Loaded all data from wiki-bios.10k.txt; saw 1382808 tokens (23362 unique)\n",
      "Generating sampling table\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus()\n",
    "corpus.load_data('wiki-bios.10k.txt', 5)\n",
    "corpus.generate_negative_sampling_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12103, 2871, 300, 7, 195, 21019, 23263, 13684, 5365, 36, 7746, 8473]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.generate_negative_samples(0, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training data\n",
    "\n",
    "Once we have the corpus ready, we need to generate our training dataset. Each instance in the dataset is a target word and positive and negative examples of contexts words. Given the target word as input, we'll want to predict (or not predict) these positive and negative context words as outputs using our network. Your task here is to create a python `list` of instances. \n",
    "\n",
    "Your final training data should be a list of tuples in the format ([target_word_id], [word_id_1, ...], [predicted_labels]), where each item in the list is a list:\n",
    "1. The first item is a list consisting only of the target word's ID.\n",
    "2. The second item is a list of word ids for both context words and negative samples \n",
    "3. The third item is a list of labels to predicted for each of the word ids in the second list (i.e., `1` for context words and `0` for negative samples). \n",
    "\n",
    "You will feed these tuples into the PyTorch `DatasetLoader` later that will do the converstion to `Tensor` objects. You will need to make sure that all of the lists in each tuple are `np.array` instances and are not plain python lists for this `Tensor` converstion to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "num_negative_samples_per_target = 2\n",
    "\n",
    "training_data = []\n",
    "    \n",
    "# Loop through each token in the corpus and generate an instance for each, \n",
    "# adding it to training_data\n",
    "ftsai_dict = dict(enumerate(corpus.full_token_sequence_as_ids))\n",
    "for word_index in ftsai_dict:\n",
    "    instance = ([],[],[])\n",
    "    # For exach target word in our dataset, select context words \n",
    "    # within +/- the window size in the token sequence\n",
    "    # For each positive target, we need to select negative examples of\n",
    "    # words that were not in the context. Use the num_negative_samples_per_target\n",
    "    # hyperparameter to generate these, using the generate_negative_samples()\n",
    "    # method from the Corpus class\n",
    "    \n",
    "    # UNK\n",
    "    if ftsai_dict[word_index] == corpus.word_to_index['<UNK>']:\n",
    "        continue\n",
    "    \n",
    "    # Append Target Word\n",
    "    instance[0].append(ftsai_dict[word_index])\n",
    "    \n",
    "    # Append Positive Sample\n",
    "    if word_index < window_size:\n",
    "        for back in list(range(0, word_index)):\n",
    "            instance[1].append(ftsai_dict[back])\n",
    "            instance[2].append(1)\n",
    "        for beyond in list(range( (word_index + 1), (word_index + window_size + 1) )):\n",
    "            instance[1].append(ftsai_dict[beyond])\n",
    "            instance[2].append(1)\n",
    "            \n",
    "    elif word_index >= len(corpus.full_token_sequence_as_ids) - window_size:\n",
    "        for back in list(range(word_index - window_size, word_index)):\n",
    "            instance[1].append(ftsai_dict[back])\n",
    "            instance[2].append(1)\n",
    "        for beyond in list(range(word_index + 1, len(corpus.full_token_sequence_as_ids))):\n",
    "            instance[1].append(ftsai_dict[beyond])\n",
    "            instance[2].append(1)\n",
    "    \n",
    "    else:\n",
    "        for back in list(range(word_index - window_size, word_index)):\n",
    "            instance[1].append(ftsai_dict[back])\n",
    "            instance[2].append(1)\n",
    "        for beyond in list(range( (word_index + 1), (word_index + window_size + 1) )):\n",
    "            instance[1].append(ftsai_dict[beyond])\n",
    "            instance[2].append(1)\n",
    "    \n",
    "    # Append Negative Sample\n",
    "    # The window size is for both the left and right, so it's 4 context words for 1 target word(with exceptions of target word at beginning and end of the corpus).\n",
    "    # 2 negatives samples for 1 positive context word in the context window, so in total 4 + 4*2 = 12 context words.Â \n",
    "    ns_size = num_negative_samples_per_target*window_size*2 + (window_size*2 - len(instance[1]))\n",
    "    instance[1].extend(corpus.generate_negative_samples(ftsai_dict[word_index], ns_size))\n",
    "    instance[2].extend([0 for i in range(ns_size)])\n",
    "    \n",
    "    # transform to np array\n",
    "    index, contexts, labels = instance\n",
    "    instance_np = (np.array(index), np.array(contexts), np.array(labels))\n",
    "    \n",
    "    # Append Instance to training_data\n",
    "    training_data.append(instance_np)\n",
    "    \n",
    "    # NOTE: this part might not make sense until later when you do the training \n",
    "    # so feel free to revisit it to see why it happens.\n",
    "    #\n",
    "    # Our training will use batches of instances together (compare that \n",
    "    # with HW1's SGD that used one item at a time). PyTorch will require\n",
    "    # that all instances in a batches have the same size, which creates an issue\n",
    "    # for us here since the target wordss at the very beginning or end of the corpus\n",
    "    # have shorter contexts. \n",
    "    # \n",
    "    # To work around these edge-cases, we need to ensure that each instance has\n",
    "    # the same size, which means it needs to have the same number of positive\n",
    "    # and negative examples. Since we are short on positive examples here (due\n",
    "    # to the edge of the corpus), we can just add more negative samples.\n",
    "    #\n",
    "    # YOUR TASK: determine what is the maximum number of context words (positive\n",
    "    # and negative) for any instance and then, for instances that have fewer than\n",
    "    # this number of context words, add in negative examples.\n",
    "    #\n",
    "    # NOTE: The maximum is fixed, so you can precompute this outside the loop\n",
    "    # ahead of time.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the network\n",
    "\n",
    "We'll create a new neural network as a subclass of `nn.Module` like we did in Homework 1. However, _unlike_ the network you built in Homework 1, we do not need to used linear layers to implement word2vec. Instead, we will use PyTorch's `Emedding` class, which maps an index (e.g., a word id in this case) to an embedding. \n",
    "\n",
    "Roughly speaking, word2vec's network makes a prediction by computing the dot product of the target word's embedding and a context word's embedding and then passing this dot product through the sigmoid function ($\\sigma$) to predict the probability that the context word was actually in the context. The homework write-up has lots of details on how this works. Your `forward()` function will have to implement this computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        \n",
    "        # Save what state you want and create the embeddings for your\n",
    "        # target and context words\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        # Once created, let's fill the embeddings with non-zero random\n",
    "        # numbers. We need to do this to get the training started. \n",
    "        #\n",
    "        # NOTE: Why do this? Think about what happens if all the embeddings\n",
    "        # are all zeros initially. What would the predictions look like for\n",
    "        # word2vec with these embeddings and how would the updated work?\n",
    "        \n",
    "        self.init_emb(init_range=0.5/vocab_size)\n",
    "        \n",
    "    def init_emb(self, init_range):\n",
    "        \n",
    "        # Fill your two embeddings with random numbers uniformly sampled\n",
    "        # between +/- init_range\n",
    "        # writing style 1\n",
    "        self.target_embeddings.weight.data.uniform_(-init_range, init_range)\n",
    "        # writing style 2\n",
    "        nn.init.uniform_(self.context_embeddings.weight, -init_range, init_range)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, target_word_id, context_word_ids):\n",
    "        ''' \n",
    "        Predicts whether each context word was actually in the context of the target word.\n",
    "        The input is a tensor with a single target word's id and a tensor containing each\n",
    "        of the context words' ids (this includes both positive and negative examples).\n",
    "        '''\n",
    "        \n",
    "        # NOTE 1: This is probably the hardest part of the homework, so you'll\n",
    "        # need to figure out how to do the dot-product between embeddings and return\n",
    "        # the sigmoid. Be prepared for lots of debugging. For some reference,\n",
    "        # our implementation is three lines and really the hard part is just\n",
    "        # the last line. However, it's usually a matter of figuring out what\n",
    "        # that one line looks like that ends up being the hard part.\n",
    "        \n",
    "        # NOTE 2: In this homework you'll be dealing with *batches* of instances\n",
    "        # rather than a single instance at once. PyTorch mostly handles this\n",
    "        # seamlessly under the hood for you (which is very nice) but batching\n",
    "        # can show in weird ways and create challenges in debugging initially.\n",
    "        # For one, your inputs will get an extra dimension. So, for example,\n",
    "        # if you have a batch size of 4, your input for target_word_id will\n",
    "        # really be 4 x 1. If you get the embeddings of those targets,\n",
    "        # it then becomes 4x50! The same applies to the context_word_ids, except\n",
    "        # that was already a list so now you have things with shape \n",
    "        #\n",
    "        #    (batch x context_words x embedding_size)\n",
    "        #\n",
    "        # One of your tasks will be to figure out how to get things lined up\n",
    "        # so everything \"just works\". When it does, the code looks surprisingly\n",
    "        # simple, but it might take a lot of debugging (or not!) to get there.\n",
    "        \n",
    "        # NOTE 3: We *strongly* discourage you from looking for existing \n",
    "        # implementations of word2vec online. Sadly, having reviewed most of the\n",
    "        # highly-visible ones, they are actually wrong (wow!) or are doing\n",
    "        # inefficient things like computing the full softmax instead of doing\n",
    "        # the negative sampling. Looking at these will likely leave you more\n",
    "        # confused than if you just tried to figure it out yourself.\n",
    "        \n",
    "        # NOTE 4: There many ways to implement this, some more efficient\n",
    "        # than others. You will want to get it working first and then\n",
    "        # test the timing to see how long it takes. As long as the\n",
    "        # code works (vector comparisons look good) you'll receive full\n",
    "        # credit. However, very slow implementations may take hours(!)\n",
    "        # to converge so plan ahead.\n",
    "        \n",
    "        \n",
    "        # Hint 1: You may want to review the mathematical operations on how\n",
    "        # to compute the dot product to see how to do these\n",
    "        \n",
    "        # Hint 2: the \"dim\" argument for some operations may come in handy,\n",
    "        # depending on your implementation\n",
    "        \n",
    "        # Hint 3: printing the shape of the tensors can come in very handy when\n",
    "        # debugging to see where things aren't lining up\n",
    "           \n",
    "        # TODO: Implement the forward pass of word2vec\n",
    "        \n",
    "        \n",
    "        w1 = self.target_embeddings(target_word_id)\n",
    "        w2 = self.context_embeddings(context_word_ids)\n",
    "\n",
    "        \n",
    "        return torch.sigmoid(torch.bmm(w1, torch.transpose(w2, 1, 2)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network!\n",
    "\n",
    "Now that you have data in the right format and a neural network designed, it's time to train the network and see if it's all working. The trainin code will look surprisingly similar at times to your pytorch code from Homework 1 since all networks share the same base training setup. However, we'll add a few new elements to get you familiar with more common training techniques. \n",
    "\n",
    "For all steps, be sure to use the hyperparameters values described in the write-up.\n",
    "\n",
    "1. Initialize your optimizer and loss function \n",
    "2. Create your network\n",
    "3. Load your dataset into PyTorch's `DataLoader` class, which will take care of batching and shuffling for us (yay!)\n",
    "4. Create a new `SummaryWriter` to periodically write our running-sum of the loss to a tensorboard\n",
    "5. Train your model \n",
    "\n",
    "Two new elements show up. First, we'll be using `DataLoader` which is going to sample data for us and put it in a batch (and also convert the data to `Tensor` objects. You can iterate over the batches and each iteration will return all the items eventually, one batch at a time (a full epoch's worth).\n",
    "\n",
    "The second new part is using `tensorboard`. As you might have noticed in Homework 1, training neural models can take some time. [TensorBoard](https://www.tensorflow.org/tensorboard/) is a handy web-based view that you can check during training to see how the model is doing. We'll use it here and periodically log a running sum of the loss after a set number of steps. The Homework write up has a plot of what this looks like. We'll be doing something simple here with tensorboard but it will come in handy later as you train larger models (for longer) and may want to visually check if your model is converging. TensorBoard was initially written for another deep learning framework, TensorFlow, but proved so useful it was ported to work in PyTorch too and is [easy to integrate](https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html).\n",
    "\n",
    "To start training, we recommend training on the `wiki-bios.10k.txt` dataset. This data is small enough you can get through an epoch in a few minutes (or less) while still being large enough you can test whether the model is learning anything by examining common words. Below this cell we've added a few helper functions that you can use to debug and query your model. In particular, the `get_neighbors()` function is a great way to test: if your model has learned anything, the nearest neighbors for common words should seem reasonable (without having to jump through mental hoops). An easy word to test on the `10k` data is \"january\" which should return month-related words as being most similar.\n",
    "\n",
    "**NOTE**: Since we're training biographies, the text itself will be skewed towards words likely to show up biographices--which isn't necessary like \"regular\" text. You may find that your model has few instances of words you think are common, or that the model learns poor or unusual neighbors for these. When querying the neighbors, it can help to think of which words you think are likely to show up in biographies on Wikipedia and use those as probes to see what the model has learned.\n",
    "\n",
    "Once you're convinced the model is learning, switch to the `med` data and train your model as specified in the PDF. Once trained, save your model using the `save()` function at the end of the notebook. This function records your data in a common format for word2vec vectors and lets you load the vectors into other libraries that have more advanced functionality. In particular, you can use the [gensim](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html) code in other notebook included to explore the vectors and do simple vector analogies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Laptop GPU'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"\n",
    "    \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b617ad368b94d84b03c43b78c2932ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d7c2b8a6e447d4a16888767c431b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.31461256742477\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.31271207332611\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.30667406320572\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.29560953378677\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.27911186218262\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.25660401582718\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.22763866186142\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.19589018821716\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.15728157758713\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.11516153812408\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.06995910406113\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:69.01872235536575\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.96987503767014\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.91266649961472\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.85320508480072\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.79050439596176\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.7196609377861\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.64809912443161\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.57650709152222\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.50820618867874\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.42917931079865\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.35621684789658\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.27729946374893\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.1942982673645\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6791, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6811, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6811, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.1383810043335\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6811, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6790, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6811, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6791, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6811, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6789, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss:68.05334168672562\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6793, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6790, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6787, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6786, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6788, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6791, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6785, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6790, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6790, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6793, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6789, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6787, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6774, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6771, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6791, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6775, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6788, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6759, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (target_embeddings): Embedding(23362, 50)\n",
       "  (context_embeddings): Embedding(23362, 50)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Set your training stuff, hyperparameters, models, tensorboard writer etc. here\n",
    "# variables\n",
    "batch_size = 512\n",
    "epochs = 1\n",
    "learning_rate = 5e-5\n",
    "vocab_size = len(corpus.index_to_word)\n",
    "embedding_size = 50\n",
    "\n",
    "# models and calculations\n",
    "model = Word2Vec(vocab_size, embedding_size)\n",
    "model.to(device)\n",
    "loss_criterion = torch.nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# HINT: wrapping the epoch/step loops in nested tqdm calls is a great way\n",
    "# to keep track of how fast things are and how much longer training will take\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "\n",
    "    loss_sum = 0\n",
    "    \n",
    "    # TODO: use your DataLoader to iterate over the data\n",
    "    for step, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        # NOTE: since you created the data as a tuple of three np.array instances,\n",
    "        # these have now been converted to Tensor objects for us\n",
    "        \n",
    "        target_ids, context_ids, labels = data    \n",
    "        \n",
    "        # TODO: Fill in all the training details here\n",
    "\n",
    "        # 1.forward\n",
    "        predict = model.forward(target_ids.to(device), context_ids.to(device))\n",
    "\n",
    "        # 2.loss\n",
    "        loss = loss_criterion(torch.squeeze(predict.float()), torch.squeeze(labels.to(device).float()))\n",
    "\n",
    "        # 3.backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # 4.optimizer step: update the weight\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 5.optimizer to 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        # TODO: Based on the details in the Homework PDF, periodically\n",
    "        # report the running-sum of the loss to tensorboard. Be sure\n",
    "        # to reset the running sum after reporting it.\n",
    "        loss_sum += loss.item()\n",
    "        if step % 100 == 99:\n",
    "            writer.add_scalar(\"Loss\", loss_sum, step)\n",
    "            print(f'loss:{loss_sum}')\n",
    "            loss_sum = 0.0\n",
    "            \n",
    "        \n",
    "        # TODO: it can be helpful to add some early stopping here after\n",
    "        # a fixed number of steps (e.g., if step > max_steps)\n",
    "#         if step == 10:\n",
    "#             break\n",
    "        \n",
    "        \n",
    "# once you finish training, it's good practice to switch to eval.\n",
    "writer.flush()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Problem 12 plot\n",
    "import matplotlib.pyplot as plt\n",
    "batch_lst = [512,256,128,64,32,8,2]\n",
    "time_lst = [21, 20, 27, 44, 78, 282, 1050]\n",
    "\n",
    "\n",
    "plt.plot(batch_lst,time_lst)\n",
    "plt.xlabel(\"batch\")\n",
    "plt.ylabel(\"time (second)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1208, -0.1127,  0.1247,  ...,  0.0403, -0.1210,  0.1147],\n",
       "        [-0.1166, -0.1045,  0.1271,  ...,  0.0107, -0.1222,  0.1091],\n",
       "        [-0.0025, -0.0019,  0.0038,  ..., -0.0030, -0.0024,  0.0022],\n",
       "        ...,\n",
       "        [-0.0085, -0.0046,  0.0102,  ..., -0.0067, -0.0080,  0.0053],\n",
       "        [-0.0036, -0.0026,  0.0035,  ...,  0.0003, -0.0031,  0.0026],\n",
       "        [-0.0035, -0.0033,  0.0041,  ...,  0.0019, -0.0036,  0.0033]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.target_embeddings.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify things are working\n",
    "\n",
    "Once you have an initial model trained, try using the following code to query the model for what are the nearest neighbor of a word. This code is intended to help you debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(model, word_to_index, target_word):\n",
    "    \"\"\" \n",
    "    Finds the top 10 most similar words to a target word\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for word, index in tqdm(word_to_index.items(), total=len(word_to_index)):\n",
    "        similarity = compute_cosine_similarity(model, word_to_index, target_word, word)\n",
    "        result = {\"word\": word, \"score\": similarity}\n",
    "        outputs.append(result)\n",
    "\n",
    "    # Sort by highest scores\n",
    "    neighbors = sorted(outputs, key=lambda o: o['score'], reverse=True)\n",
    "    return neighbors[1:11]\n",
    "\n",
    "def compute_cosine_similarity(model, word_to_index, word_one, word_two):\n",
    "    '''\n",
    "    Computes the cosine similarity between the two words\n",
    "    '''\n",
    "    try:\n",
    "        word_one_index = word_to_index[word_one]\n",
    "        word_two_index = word_to_index[word_two]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "    embedding_one = model.target_embeddings(torch.LongTensor([word_one_index]))\n",
    "    embedding_two = model.target_embeddings(torch.LongTensor([word_two_index]))\n",
    "    similarity = 1 - abs(float(cosine(embedding_one.detach().numpy(),\n",
    "                                      embedding_two.detach().numpy())))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3784b890644d168ed33fa0dc9e8995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'word': 'april', 'score': 0.9999831318855286},\n",
       " {'word': 'december', 'score': 0.999962329864502},\n",
       " {'word': 'june', 'score': 0.9999588131904602},\n",
       " {'word': 'february', 'score': 0.9999216198921204},\n",
       " {'word': 'october', 'score': 0.9999107122421265},\n",
       " {'word': 'january', 'score': 0.9999023675918579},\n",
       " {'word': 'july', 'score': 0.999843955039978},\n",
       " {'word': 'november', 'score': 0.999737560749054},\n",
       " {'word': 'september', 'score': 0.9995895028114319},\n",
       " {'word': 'august', 'score': 0.9995672106742859}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "get_neighbors(model, corpus.word_to_index, \"march\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05af7d1298a748c7a7df5441275afbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'word': 'september', 'score': 0.999951183795929},\n",
       " {'word': 'june', 'score': 0.9999493956565857},\n",
       " {'word': 'august', 'score': 0.9999356269836426},\n",
       " {'word': 'october', 'score': 0.9999343156814575},\n",
       " {'word': 'december', 'score': 0.9999210238456726},\n",
       " {'word': 'march', 'score': 0.9999067187309265},\n",
       " {'word': 'april', 'score': 0.999883770942688},\n",
       " {'word': 'waived', 'score': 0.9996583461761475},\n",
       " {'word': 'estadio', 'score': 0.9993149638175964},\n",
       " {'word': '24th', 'score': 0.9992900490760803}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neighbors(model, corpus.word_to_index, \"january\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your model!\n",
    "\n",
    "Once you have a fully trained model, save it using the code below. Note that we only save the `target_embeddings` from the model, but you could modify the code if you want to save the context vectors--or even try doing fancier things like saving the concatenation of the two or the average of the two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, corpus, filename):\n",
    "    '''\n",
    "    Saves the model to the specified filename as a gensim KeyedVectors in the\n",
    "    text format so you can load it separately.\n",
    "    '''\n",
    "\n",
    "    # Creates an empty KeyedVectors with our embedding size\n",
    "    kv = KeyedVectors(vector_size=embedding_size)        \n",
    "    vectors = []\n",
    "    words = []\n",
    "    # Get the list of words/vectors in a consistent order\n",
    "    for index in trange(model.target_embeddings.num_embeddings):\n",
    "        word = corpus.index_to_word[index]\n",
    "        vectors.append(model.target_embeddings(torch.LongTensor([index])).detach().numpy()[0])\n",
    "        words.append(word)\n",
    "\n",
    "    # Fills the KV object with our data in the right order\n",
    "    kv.add_vectors(words, vectors) \n",
    "    kv.save_word2vec_format(filename, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2481941520d48c6913d1ca57eddd8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save(model, corpus, 'output_vec_2.kv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PART: DO THIS LAST AND READ CAREFULLY\n",
    "\n",
    "Before you start this part, you need to have a fully working solution and completed the exploratory part of the assignment.\n",
    "\n",
    "**Once you are ready, create a copy of your working notebook and call it `Debiased Word2Vec.ipynb`. Do not do this part in your working code for the assignment!!!**\n",
    "\n",
    "## Seriously, save your code in a new file and then start reading the rest of these instructions there.\n",
    "\n",
    "Ok, hopefully you're reading these in a new file... For this last part of the assignment, we're going to _change_ how word2vec learns at a fundamental level. \n",
    "\n",
    "As you might have noticed in your exploratory analysis, the word2vec model learns to weird and sometimes biased associations between words. In particular, your word2vec model has likely learned some unfortunate gender biases, e.g., that the vector for \"nurse\" is closer to \"woman\" than \"man\". The algorithm itself isn't to blame since it is learning these from a corpus (here, Wikipedia biographies) that contain biases already based on how people write. Wikipedia [is](http://markusstrohmaier.info/documents/2015_icwsm2015_wikipedia_gender.pdf) [well](http://dcs.gla.ac.uk/~mounia/Papers/wiki_gender_bias.pdf) [known](https://www.academia.edu/download/64856696/genderanalysisofWikipediabiostext_self_archived.pdf) for having gender biases in how it writes about men and women.\n",
    "\n",
    "\n",
    "**Side note**: Some times this bias-learning behavior is useful: We can use word2vec to uncover these biases and analyze their trends, like this PNAS paper did for [looking at bias in news writing along multiple dimensions of identity](https://www.pnas.org/content/pnas/115/16/E3635.full.pdf)\n",
    "\n",
    "In this last part of the homework, we'll ask how we might try to _prevent_ these biases by modifying the training. You won't need to solve this problem by any means, but the act of trying to reduce the biases will open up a whole new toolbox for how you (the experimenter/practioner) can change how and what models learn.\n",
    "\n",
    "There are many potential ways to _debias_ word embeddings so that their representations are not skewed along one \"latent dimension\" like gender. In this homework, you'll be trying one of a few different ideas for how to do it. **You are not expected to solve gender bias! This part of the assignment is to have to start grappling with a hard challenge but there is no penalty for doing less-well!** \n",
    "\n",
    "One common technique to have models avoid learning bias is similar to another one you already&mdash;**regularization**. In Logistic Regression, we could use L2 regularization to have our model avoid learning $\\beta$ weights that are overfit to specific or low-frequency features by adding a regularizer penalty where the larger the weight, the more penalty the model paid. Recall that this forces the model to only pick the most useful (generalizable) weights, since it has to pay a penalty for any non-zero weight. \n",
    "\n",
    "In word2vec, we can adapt the idea to think about whether our model's embeddings are closer or farther to different gender dimensions. For example, if we consider the embedding for \"president\", ideally, we'd want it to be equally similar to the embeddings for \"man\" and \"woman\". One idea then is to penalize the model based on how uneven the similarity is. We can do this by directly modifying the loss:\n",
    "```\n",
    "loss = loss_criteron(preds, actual_vals) + some_bias_measuring_function(model)\n",
    "```\n",
    "Here, the `some_bias_measuring_function` function takes in your model as input and returns how much bias you found. Continuing our example, we might implement it in pseudocode as\n",
    "```\n",
    "def some_bias_measuring_function(model):\n",
    "    pres_woman_sim = cosine_similarity(model, \"president\", \"woman\")\n",
    "    pres_man_sim = cosine_similarity(model, \"president\", \"man\")\n",
    "    return abs(pres_woman_sim - pres_man_sim)\n",
    "```\n",
    "This simple example would penalize the model for learning a representation of \"president\" that is more simular to one of the two words. Of course, this example is overly simple. Why just \"president\"? Why just \"man\" and \"woman\"? Why not other words or other gender-related words or other gender identities?? \n",
    "\n",
    "Another idea might be to just make the vectors for \"man\" and \"woman\" be as similar as possible:\n",
    "```\n",
    "def some_bias_measuring_function(model):\n",
    "    # cosine similarity is in [-1,1] but we mostly expect it in [0,1]\n",
    "    man_woman_sim = cosine_similarity(model, \"man\", \"woman\")\n",
    "    # penalize vectors that are not maximally similar, and avoid the edge case \n",
    "    # of negative cosine similarity\n",
    "    return 1 - max(man_woman_sim, 0)\n",
    "```\n",
    "\n",
    "All of this works in practice because PyTorch is fantastic about tracking the gradient with respect to the loss. This ability lets us easily define a loss function so that our word2vec model (1) learns to predict the right context words while (2) avoids learning biases. If we compare this code to the numpy part of Homework 1, it's easy to see how powerful PyTorch can be as an experimenter for helping you control what and how your models learn!\n",
    "\n",
    "Your task is to expand this general approach by coming up with an extension to word2vec that adds some new term to the `loss` value that penalizes bias in the gender dimension. There is no right way to do this and even some right-looking approaches may not work&mdash;or might word but simultaneously destroy the information in the word vectors (all-zero vectors are unbiased but also uninformative!). \n",
    "\n",
    "**Suggestion:** You may need to weight your bias term in the loss function (remember that $\\lambda_1 x_1 + \\lambda_2 x_2$ interpolation? This is sort of similar) so that your debiasing regularizer doesn't overly penalize your model.\n",
    "\n",
    "Once you have generated your model, record word vector similarities for the pairs listed on canvas in `word-pair-similarity-predictions.csv` where your file writes a result like\n",
    "```\n",
    "word1,word2,sim\n",
    "dog,puppy,0.91234123\n",
    "woman,preseident,0.81234\n",
    "```\n",
    "You'll record the similarity for each pair of words in the file and upload it to CodaLab, which is kind of like Kaggle but lets use a custom scoring program. We'll evaluate your embeddings based on how unbiased they are and how much information they still capture after debiasing. **Your grade does not depend on how well you do in CodaLab, just that you tried something and submitted.** However, the CodaLab leaderboard will hopefully provide a fun and insightful way of comparing just how much bias we can remove from our embeddings.\n",
    "\n",
    "The CodaLab link will be posted to Piazza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output for codalab\n",
    "import pandas as pd\n",
    "test_df = pd.read_csv('word_pair_similarity_predictions.csv')\n",
    "\n",
    "word1 = test_df['word1'].to_list()\n",
    "word2 = test_df['word2'].to_list()\n",
    "final_list = []\n",
    "\n",
    "for i in range(len(word1)):\n",
    "    final_list.append(compute_cosine_similarity(model, corpus.word_to_index, word1[i], word2[i]))\n",
    "\n",
    "test_df['sim'] = final_list\n",
    "# test_df.sort_values(by = 'sim')\n",
    "\n",
    "test_df.to_csv('output_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>cow</td>\n",
       "      <td>cattle</td>\n",
       "      <td>0.981979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>book</td>\n",
       "      <td>story</td>\n",
       "      <td>0.994583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>winter</td>\n",
       "      <td>summer</td>\n",
       "      <td>0.987903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>taxi</td>\n",
       "      <td>cab</td>\n",
       "      <td>0.980690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tree</td>\n",
       "      <td>maple</td>\n",
       "      <td>0.444423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>bed</td>\n",
       "      <td>bedroom</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>roof</td>\n",
       "      <td>ceiling</td>\n",
       "      <td>0.912390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>disease</td>\n",
       "      <td>infection</td>\n",
       "      <td>0.932271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>arm</td>\n",
       "      <td>shoulder</td>\n",
       "      <td>0.871682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>sheep</td>\n",
       "      <td>lamb</td>\n",
       "      <td>0.980650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1      word2       sim\n",
       "140      cow     cattle  0.981979\n",
       "141     book      story  0.994583\n",
       "142   winter     summer  0.987903\n",
       "143     taxi        cab  0.980690\n",
       "144     tree      maple  0.444423\n",
       "145      bed    bedroom  0.997630\n",
       "146     roof    ceiling  0.912390\n",
       "147  disease  infection  0.932271\n",
       "148      arm   shoulder  0.871682\n",
       "149    sheep       lamb  0.980650"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('word_pair_similarity_predictions.csv')\n",
    "\n",
    "word1 = df['word1'].to_list()\n",
    "word2 = df['word2'].to_list()\n",
    "lst = []\n",
    "\n",
    "for i in range(len(word1)):\n",
    "    lst.append(compute_cosine_similarity(model, corpus.word_to_index, word1[i], word2[i]))\n",
    "\n",
    "df['sim'] = lst\n",
    "df[140:150]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
