{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f459673-1587-4f16-817a-7c79db3a3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import krippendorff as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493ffb05-d07e-4bf0-a804-93b7d00989ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the file\n",
    "annotation = pd.read_csv('annotation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "135b18b8-07bb-47ba-9d1d-11f04fbb2cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_n28cas</td>\n",
       "      <td>user1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_n28cas</td>\n",
       "      <td>user2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_n28cas</td>\n",
       "      <td>user3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_n2bb3g</td>\n",
       "      <td>user1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_n2bb3g</td>\n",
       "      <td>user2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id annotator  rating\n",
       "0  t3_n28cas     user1       2\n",
       "1  t3_n28cas     user2       1\n",
       "2  t3_n28cas     user3       2\n",
       "3  t3_n2bb3g     user1       4\n",
       "4  t3_n2bb3g     user2       3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5917f21-41a7-49d1-b4a0-a2e8a6c41634",
   "metadata": {},
   "source": [
    "### Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e1b49-8b66-4488-9f07-4d6f005d78d8",
   "metadata": {},
   "source": [
    "1. Compute r and the compute α using the ordinal and nominal level of measurements for the\n",
    "group member’s annotations and report them (three scores total).Compute r and the compute α using the ordinal and nominal level of measurements for the group member’s annotations and report them (three scores total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4792a79f-96af-4189-b220-16ad0c6252ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>annotator</th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>user3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annotator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172092</td>\n",
       "      <td>0.778475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user2</th>\n",
       "      <td>0.172092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user3</th>\n",
       "      <td>0.778475</td>\n",
       "      <td>0.094668</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "annotator     user1     user2     user3\n",
       "annotator                              \n",
       "user1      1.000000  0.172092  0.778475\n",
       "user2      0.172092  1.000000  0.094668\n",
       "user3      0.778475  0.094668  1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pearson Correlation r\n",
    "annotation_table = annotation.pivot(index='id', columns='annotator', values='rating')\n",
    "annotation_table.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f71e50-4dc5-466f-b05c-f52eb80bea16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotation_rd = [annotation_table['user1'].to_list(), annotation_table['user2'].to_list(), annotation_table['user3'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33250231-1aaa-4ce6-824d-af97667d79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# krippendorff alpha nominal and ordinal\n",
    "kr_alpha_nominal = kr.alpha(reliability_data= annotation_rd,level_of_measurement=\"nominal\")\n",
    "kr_alpha_ordinal = kr.alpha(reliability_data= annotation_rd,level_of_measurement=\"ordinal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1748af58-a657-4f5e-a0ab-738aade9def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nominal krippendorff alpha: 0.163187944045861\n",
      "ordinal krippendorff alpha: 0.22116451634036827\n"
     ]
    }
   ],
   "source": [
    "print(f'nominal krippendorff alpha: {kr_alpha_nominal}')\n",
    "print(f'ordinal krippendorff alpha: {kr_alpha_ordinal}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bb9c34-150b-4225-a798-72c2fe682a5a",
   "metadata": {},
   "source": [
    "2. In 2-3 sentences, comment on the difference (if any) between your group r and the α scores. Which is higher and what do you think this means?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f10923-d4a0-4d36-b4ac-c51ce8acdf39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11b8350-cb01-4b29-babc-46157bdb4b39",
   "metadata": {},
   "source": [
    "3. In 2-3 sentences, comment on the difference (if any) between your group’s ordinal and nominal α scores. Which is higher and what do you think this means? Which one should you use in practice to measure agreement in this setting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5313be8a-0267-425b-a774-4a0bc146f752",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c359069f-6f39-4427-bfc7-db3ca5e5ec65",
   "metadata": {},
   "source": [
    "### Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b62ea2-9fd1-4ebc-86ef-63cd4016951a",
   "metadata": {},
   "source": [
    "Once all the annotations are released, compute the agreement of all the other annotators on your group’s items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7696d127-8128-495f-93ea-922e14d5e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('si630w22-hw3-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2affe656-eb3e-411b-aff9-c507ef750756",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_have_our_item = sorted(train_data['group'].unique())\n",
    "output_lst = []\n",
    "\n",
    "for group in group_have_our_item:\n",
    "    other_group = train_data[(train_data['id'].isin(annotation['id'])) & (train_data['group'] == group) ]\n",
    "    other_group_table = other_group.pivot(index='id', columns='annotator_id', values='rating')\n",
    "    \n",
    "    annotation_rel_data = []\n",
    "    for annotator in other_group['annotator_id'].unique():\n",
    "        annotation_rel_data.append(other_group_table[annotator].to_list())\n",
    "\n",
    "    kr_alpha_o_other_group = kr.alpha(reliability_data=annotation_rel_data,level_of_measurement=\"ordinal\")\n",
    "    \n",
    "\n",
    "    output_lst.append([group, len(other_group_table), kr_alpha_o_other_group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33abadc1-d69c-4ed8-8c59-87f348c59863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>questions_covered</th>\n",
       "      <th>ordinal_krippendorff_alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>group_01</td>\n",
       "      <td>12</td>\n",
       "      <td>0.555026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group_02</td>\n",
       "      <td>17</td>\n",
       "      <td>0.717018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>group_03</td>\n",
       "      <td>12</td>\n",
       "      <td>0.403527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>group_04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.768293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>group_05</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.233699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>group_07</td>\n",
       "      <td>12</td>\n",
       "      <td>0.819820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>group_08</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.773769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>group_09</td>\n",
       "      <td>11</td>\n",
       "      <td>0.505931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>group_10</td>\n",
       "      <td>302</td>\n",
       "      <td>0.202908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>group_11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.004512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>group_12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.899683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>group_13</td>\n",
       "      <td>16</td>\n",
       "      <td>0.442544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>group_14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.687603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>group_15</td>\n",
       "      <td>13</td>\n",
       "      <td>0.868610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>group_16</td>\n",
       "      <td>13</td>\n",
       "      <td>0.668842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>group_17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.714722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>group_18</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.046525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>group_19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.542088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>group_20</td>\n",
       "      <td>12</td>\n",
       "      <td>0.646140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>group_21</td>\n",
       "      <td>13</td>\n",
       "      <td>0.900100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>group_22</td>\n",
       "      <td>13</td>\n",
       "      <td>0.120157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>group_23</td>\n",
       "      <td>12</td>\n",
       "      <td>0.841139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>group_24</td>\n",
       "      <td>15</td>\n",
       "      <td>0.219661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>group_25</td>\n",
       "      <td>12</td>\n",
       "      <td>0.925854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       group  questions_covered  ordinal_krippendorff_alpha\n",
       "0   group_01                 12                    0.555026\n",
       "1   group_02                 17                    0.717018\n",
       "2   group_03                 12                    0.403527\n",
       "3   group_04                 10                    0.768293\n",
       "4   group_05                 12                   -0.233699\n",
       "5   group_07                 12                    0.819820\n",
       "6   group_08                 12                   -0.773769\n",
       "7   group_09                 11                    0.505931\n",
       "8   group_10                302                    0.202908\n",
       "9   group_11                 14                    0.004512\n",
       "10  group_12                 11                    0.899683\n",
       "11  group_13                 16                    0.442544\n",
       "12  group_14                 11                    0.687603\n",
       "13  group_15                 13                    0.868610\n",
       "14  group_16                 13                    0.668842\n",
       "15  group_17                 13                    0.714722\n",
       "16  group_18                 12                   -0.046525\n",
       "17  group_19                  9                    0.542088\n",
       "18  group_20                 12                    0.646140\n",
       "19  group_21                 13                    0.900100\n",
       "20  group_22                 13                    0.120157\n",
       "21  group_23                 12                    0.841139\n",
       "22  group_24                 15                    0.219661\n",
       "23  group_25                 12                    0.925854"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=output_lst, columns = ['group','questions_covered','ordinal_krippendorff_alpha'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837c34b-c8e7-4d0d-a5e0-4e24913d4d1a",
   "metadata": {},
   "source": [
    "In a 2-3 sentences, comment on the difference (if any) between your group’s and other students’ agreement and what you think is the cause. We recommend looking at other groups’ guidelines at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df07a9e-ad25-4a8a-a64d-034b89b99bd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84149c61-a78f-4621-8e6d-122919483bc4",
   "metadata": {},
   "source": [
    "### Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4084f7-afc6-4a27-ae0a-4bf1865de734",
   "metadata": {},
   "source": [
    "For each item, compute the mean score for the group’s ratings and the mean score for another group of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc54fe64-6b81-4681-ae8e-bf184fa2e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_table_our_all = annotation.groupby('id').mean()\n",
    "mean_table_other_all = train_data[train_data['group'] != 'group_10'].groupby('id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2a2bbd3-6692-4952-bc85-0a9bae12008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join_mean_table = mean_table_our_all.join(mean_table_other_all, on='id',how='inner', lsuffix='_our', rsuffix='_other')\n",
    "inner_join_mean_table['difference'] = abs(inner_join_mean_table['rating_our'] - inner_join_mean_table['rating_other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bafa9db-f540-4840-8324-53dc772727fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_our</th>\n",
       "      <th>rating_other</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t3_nir04f</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_nns7v4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_n4chfq</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_n30vyc</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_n7oluj</th>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_nap4rx</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_ng334p</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_n30alr</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_nbhhux</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_nls959</th>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rating_our  rating_other  difference\n",
       "id                                             \n",
       "t3_nir04f    4.666667      1.333333    3.333333\n",
       "t3_nns7v4    5.000000      1.666667    3.333333\n",
       "t3_n4chfq    5.000000      2.000000    3.000000\n",
       "t3_n30vyc    2.000000      5.000000    3.000000\n",
       "t3_n7oluj    4.333333      1.500000    2.833333\n",
       "t3_nap4rx    2.333333      5.000000    2.666667\n",
       "t3_ng334p    5.000000      2.333333    2.666667\n",
       "t3_n30alr    5.000000      2.500000    2.500000\n",
       "t3_nbhhux    2.666667      5.000000    2.333333\n",
       "t3_nls959    4.333333      2.000000    2.333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the mean score for the group’s ratings and the mean score for another group of students\n",
    "inner_join_mean_table.sort_values(by='difference',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59b1c5-e0b8-4dfd-85d4-86b1bee62940",
   "metadata": {},
   "source": [
    "In your report, include the text from each of these 10 replies and what the ratings were for each group. Describe why you think the two were different, ideally pointing to differences in the two group’s guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e856a1-2904-4be0-b49b-87ee1ef56505",
   "metadata": {},
   "source": [
    "After a discussion with your group members, adjudicate the rating and decide what is the final “true” rating, examining all the evidence. If you changed your score, in one sentence, state what led you to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1090a09-058f-4f8f-af58-be2a101e864b",
   "metadata": {},
   "source": [
    "### Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e695d93-1fde-4d8c-b801-6a6d7fba9e11",
   "metadata": {},
   "source": [
    "Based on your analysis of annotator agreement and the disagreements and the different annotation guidelines, provide at least specific improvements that could be made to your own guidelines to improve annotator agreement. Improvements should be a series of bullet points, each describing in at least 1-2 sentences the changes that would be made to increase annotator agreement or correct for gaps and edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb88a3-9cb8-4211-bd30-b730a976c723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0818d4b1-fb69-4a10-bc64-cbe172868a2e",
   "metadata": {},
   "source": [
    "### Problem 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49580cee-36de-47a7-8975-32e6c39a3f45",
   "metadata": {},
   "source": [
    "#### Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ccdff0-b535-4652-a7c8-4de92147f6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622f8fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5620e31-6d60-44d3-b8a1-9ac9e8a9f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "100b02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio===0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d93d7a-496e-44b8-b3e3-3a38a0c14e54",
   "metadata": {},
   "source": [
    "### Problem 11 and 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc98329-1aa2-4dc1-8903-59971fbab51b",
   "metadata": {},
   "source": [
    "#### 11.1 The Huggingface Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # debug\n",
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58e2b41f-8810-41f2-8c6e-9bd84d67c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "from sklearn.metrics import f1_score, mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d66fcdd-0c77-4f36-b546-13efb6344f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df87745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "978916c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "281e084a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8162be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Laptop GPU'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d5ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bf0d293-1ae9-496f-9993-a078a67c7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('si630w22-hw3-train.csv')\n",
    "test_data = pd.read_csv('si630w22-hw3-test.public.csv')\n",
    "text_data = pd.read_csv('si630w22-hw3-data.csv')\n",
    "dev_data = pd.read_csv('si630w22-hw3-dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b418a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data['text'] = text_data[['question_text', 'reply_text']].agg(' [SEP] '.join, axis=1)\n",
    "\n",
    "def load_data_to_dataset(text_df, df, is_test_data = False):\n",
    "\n",
    "    if is_test_data == True:\n",
    "        df_processed = df.groupby('id').count()\n",
    "        merge_df = pd.merge(df_processed, text_df, left_on='id',right_on='question_id',how='inner')\n",
    "        data = merge_df[['question_id','text']]\n",
    "        \n",
    "#         output = Dataset.from_pandas(data, preserve_index=False)\n",
    "        output = data\n",
    "        \n",
    "    else:\n",
    "        df_processed = df.groupby('id').mean('rating')\n",
    "        merge_df = pd.merge(df_processed, text_df, left_on='id',right_on='question_id',how='inner')\n",
    "        \n",
    "        data = merge_df[['question_id','text','rating']]\n",
    "        data = data.rename(columns={'rating': 'labels'})\n",
    "        data['labels']= data['labels']\n",
    "    \n",
    "        output = Dataset.from_pandas(data, preserve_index=False)\n",
    "\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a78bab83-730d-4a50-962c-63a900d01358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the tokenizer\n",
    "# Call the pretrained model\n",
    "model_ckpt = 'microsoft/MiniLM-L12-H384-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "19bb1c40-011e-4664-a893-bfab84b31f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aff07b48b634b0ab4f645c671714111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = load_data_to_dataset(text_data, train_data, is_test_data = False)\n",
    "train_ds = train_ds.map(tokenize_text, batched=True)\n",
    "\n",
    "dev_ds = load_data_to_dataset(text_data, dev_data, is_test_data = False)\n",
    "dev_ds = dev_ds.map(tokenize_text, batched=True)\n",
    "\n",
    "test_ds = load_data_to_dataset(text_data, test_data, is_test_data = True)\n",
    "# test_ds = test_ds.map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606461d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification as AMFSC\n",
    "model = AMFSC.from_pretrained(model_ckpt, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "827d4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    mse = mean_absolute_error(labels, preds)\n",
    "    return {'mse': mse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88cb5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "batch_size = 32\n",
    "\n",
    "logging_steps = len(train_ds) // batch_size\n",
    "output_dir = 'minln-finetuned-rating-regression'\n",
    "training_args = TrainingArguments(output_dir=output_dir,\n",
    "                                  num_train_epochs=5,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "#                                   weight_decay=0.01,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=False,\n",
    "                                  fp16=True\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d91d1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model = model, \n",
    "                  args = training_args, \n",
    "                  train_dataset = train_ds, \n",
    "                  eval_dataset = dev_ds,\n",
    "                  compute_metrics = compute_metrics,\n",
    "                  tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58753051-51d7-42d6-95b7-94cc18ba6a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id. If text, question_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/conanwu/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3779\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 595\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [595/595 02:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.924600</td>\n",
       "      <td>1.569798</td>\n",
       "      <td>1.083634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.481406</td>\n",
       "      <td>0.549081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.452900</td>\n",
       "      <td>0.453639</td>\n",
       "      <td>0.528207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.445909</td>\n",
       "      <td>0.521958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.388700</td>\n",
       "      <td>0.427893</td>\n",
       "      <td>0.508086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id. If text, question_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id. If text, question_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id. If text, question_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id. If text, question_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to minln-finetuned-rating-regression/checkpoint-500\n",
      "Configuration saved in minln-finetuned-rating-regression/checkpoint-500/config.json\n",
      "Model weights saved in minln-finetuned-rating-regression/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in minln-finetuned-rating-regression/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in minln-finetuned-rating-regression/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id. If text, question_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 811\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=595, training_loss=1.784789664204381, metrics={'train_runtime': 145.1117, 'train_samples_per_second': 130.21, 'train_steps_per_second': 4.1, 'total_flos': 1069826491272504.0, 'train_loss': 1.784789664204381, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ef084",
   "metadata": {},
   "source": [
    "#### 11.2 Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6377193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "location = '/home/conanwu/minln-finetuned-rating-regression/checkpoint-500'\n",
    "pipe = pipeline(\"text-classification\", model=location, function_to_apply=\"none\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9238ce02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 4.219916820526123}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 1 from training csv\n",
    "pipe(\"So what is the best headphones for people who love bass ? [SEP] I prefer Raycon Performance Ear Buds. They are small and light weight so they don’t get in the way of my cast. And they are water resistant Incase they fall off the fishing boat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b917a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 4.479048728942871}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t3_n2xpm3 (in dev csv file)\n",
    "pipe(\"ELI5: How do analog signals (magnetic tape in particular) work? [SEP] It’s varying levels. Think of a photograph on film, which is functionally infinite resolution as far as human eyeballs are concerned (you can’t see any pixels). With magnetic tape, you feed a varying electric signal to the write-head of the tape recorder and it “writes” an equivalent magnetic field to the tape. When you run that same tape past a read-head later, the magnetic field of the tape re-creates the same electric signal (after amplification). There’s actually no difference between analog and digital here...all tapes are physically analog. It’s just a matter of how the reading machine interprets the electrical signal. If the electrical signal coming out is a copy of what came from, say, a TV camera, then you feed that output signal to a TV, then you recreate the image the camera saw.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57d52742-1909-4851-b6ba-aae9cbdcae42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.479048728942871"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pipe(\"ELI5: How do analog signals (magnetic tape in particular) work? [SEP] It’s varying levels. Think of a photograph on film, which is functionally infinite resolution as far as human eyeballs are concerned (you can’t see any pixels). With magnetic tape, you feed a varying electric signal to the write-head of the tape recorder and it “writes” an equivalent magnetic field to the tape. When you run that same tape past a read-head later, the magnetic field of the tape re-creates the same electric signal (after amplification). There’s actually no difference between analog and digital here...all tapes are physically analog. It’s just a matter of how the reading machine interprets the electrical signal. If the electrical signal coming out is a copy of what came from, say, a TV camera, then you feed that output signal to a TV, then you recreate the image the camera saw.\")\n",
    "test[0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "723ba6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_score(text):\n",
    "    return pipe(text)[0]['score']\n",
    "\n",
    "test_ds['predicted'] = test_ds['text'].apply(return_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40c97d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prediction to csv\n",
    "final_output = test_ds[['question_id', 'predicted']]\n",
    "final_output = final_output.rename(columns={\"question_id\": \"id\"})\n",
    "final_output.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce0817-be87-4c60-aaf8-a33421680e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
